{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Xu2WWncO6ElL",
        "JXjx6s2z6IiY",
        "QWTkli2k6GGd",
        "aHfJkWHLGzcC",
        "6ayaQOu0Ll1M"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu2WWncO6ElL"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H06EKcnhxLcM"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXjx6s2z6IiY"
      },
      "source": [
        "## Download and Prepare the Dataset\n",
        "\n",
        "in this experiment, I will use the colab built-in dataset-\"mnist_train_small.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")"
      ],
      "metadata": {
        "id": "SbcTIaTktayQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=data.iloc[:,1:]"
      ],
      "metadata": {
        "id": "XLwBS0VnvpFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "RK9YVj5CvuD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.to_numpy().reshape(-1,28,28,1)"
      ],
      "metadata": {
        "id": "82DvGxCuvXLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(np.float32) / 255 * 2. - 1."
      ],
      "metadata": {
        "id": "HaqENskqtwqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWTkli2k6GGd"
      },
      "source": [
        "## define the function to plot images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91DeiLbpxv5_"
      },
      "source": [
        "def plot_results(images, n_cols=None):\n",
        "    '''visualizes fake images'''\n",
        "    display.clear_output(wait=False)\n",
        "\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "\n",
        "    if images.shape[-1] == 1:\n",
        "        images = np.squeeze(images, axis=-1)\n",
        "\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### demonstrate image samples"
      ],
      "metadata": {
        "id": "OldZDvJOxSIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(X_train[0:32,:,:,0], 8)"
      ],
      "metadata": {
        "id": "Uw62dYr5xBQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl5uWcOMxg8A"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "# create batches of tensors to be fed into the model\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "dataset = dataset.shuffle(1000)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKsQkQun6MYE"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHfJkWHLGzcC"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWnY7jRxfboU"
      },
      "source": [
        "random_normal_dimensions = 100\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(7 * 7 * 128, input_shape=[random_normal_dimensions]),\n",
        "    keras.layers.Reshape([7, 7, 128]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                                 activation=\"selu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                                 activation=\"tanh\"),\n",
        "])\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### display fake images from untrained generator"
      ],
      "metadata": {
        "id": "W1ncqnvgyh8B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ7KPXTp_49h"
      },
      "source": [
        "test_noise = tf.random.normal([32, random_normal_dimensions])\n",
        "\n",
        "# feed the batch to the untrained generator\n",
        "test_image = generator(test_noise)\n",
        "\n",
        "# visualize sample output\n",
        "plot_results(test_image, n_cols=8)\n",
        "\n",
        "print(f'shape of the generated batch: {test_image.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ayaQOu0Ll1M"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRpxEFCQ_J0x"
      },
      "source": [
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2),\n",
        "                        input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqJIlaNUMwNT"
      },
      "source": [
        "## DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIuauNaX_LUd"
      },
      "source": [
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd8o7Orz6jS7"
      },
      "source": [
        "## Configure the Model for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOy61losflZ-"
      },
      "source": [
        "from tensorflow.keras import Model, losses\n",
        "\n",
        "discriminator.compile(loss=losses.BinaryCrossentropy(), optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5XWApPx6PqB"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXWf5qn5xCeQ"
      },
      "source": [
        "def train_gan(gan, dataset, random_normal_dimensions, n_epochs=50):\n",
        "\n",
        "    generator, discriminator = gan.layers\n",
        "    dloss=[]\n",
        "    gloss=[]\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "        for real_images in dataset:\n",
        "            # infer batch size from the training batch\n",
        "            batch_size = real_images.shape[0]\n",
        "\n",
        "            # Train the discriminator - PHASE 1\n",
        "            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n",
        "            fake_images = generator(noise)\n",
        "\n",
        "            mixed_images = tf.concat([fake_images, real_images], axis=0)\n",
        "            discriminator_labels = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(mixed_images, discriminator_labels)\n",
        "\n",
        "            #print Discriminator Loss\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "              discriminator_loss = losses.BinaryCrossentropy()(tf.ones_like(discriminator(real_images)), discriminator(real_images))\n",
        "              discriminator_loss += losses.BinaryCrossentropy()(tf.zeros_like(discriminator(fake_images)), discriminator(fake_images))\n",
        "              gradients = tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
        "\n",
        "\n",
        "\n",
        "            # Train the generator - PHASE 2\n",
        "            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n",
        "            generator_labels = tf.constant([[1.]] * batch_size)\n",
        "\n",
        "            # freeze the discriminator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            # train the GAN on the noise with the labels all set to be true\n",
        "            gan.train_on_batch(noise, generator_labels)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "              generator_loss = losses.BinaryCrossentropy()(tf.ones_like(discriminator(fake_images)), discriminator(fake_images))\n",
        "              gradients = tape.gradient(generator_loss, generator.trainable_variables)\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, Discriminator Loss: {discriminator_loss.numpy():.4f}, Generator Loss: {generator_loss.numpy():.4f}\")\n",
        "        dloss.append(discriminator_loss.numpy())\n",
        "        gloss.append(generator_loss.numpy())\n",
        "\n",
        "    return generator,dloss,gloss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKsXGD_NfqPJ"
      },
      "source": [
        "n_epochs=100\n",
        "generator,dloss,gloss=train_gan(gan, dataset, random_normal_dimensions, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(n_epochs),dloss,label=\"discriminator loss\")\n",
        "plt.plot(range(n_epochs),gloss,label=\"generator loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9w1V5XjH-5MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### display the fake images from generator after 20 epochs training"
      ],
      "metadata": {
        "id": "0UkNLx3U1SDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sythetic_data(generator,num_dt,random_normal_dimensinos):\n",
        "  noise=tf.random.normal(shape=(num_dt,random_normal_dimensinos))\n",
        "  sythetic_data=generator(noise)\n",
        "  return sythetic_data"
      ],
      "metadata": {
        "id": "8kRVg1uV2Yuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sythetic_images = sythetic_data(generator,32,random_normal_dimensions)\n",
        "\n",
        "plot_results(sythetic_images, 8)"
      ],
      "metadata": {
        "id": "9sTA0B7br0p2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}